# CONTEXT.md

## Project Summary

**Project Genesis** is a comprehensive, hands-on learning initiative designed to build and manage a multi-service application within a modern **DevOps ecosystem**. It serves as a real-world sandbox demonstrating best practices across **DevOps, Site Reliability Engineering (SRE), DevSecOps, and FinDevOps**. The core application, the **AuditFlow Platform**, is orchestrated on a **Kubernetes (K3s)** cluster, showcasing the entire software delivery lifecycle from infrastructure provisioning to application deployment and ongoing operations, all managed as code.

---

## Project Goals

The primary goals of Project Genesis are to provide practical experience in:
* Designing and deploying the **AuditFlow Platform** in a Kubernetes environment.
* Implementing **Infrastructure as Code (IaC)** for consistent and automated infrastructure provisioning.
* Building robust **CI/CD pipelines** for continuous integration and delivery.
* Managing Kubernetes resources effectively using **Helm and Kustomize**.
* Integrating **testing and code quality** into the development workflow.
* Establishing **observability** for monitoring application health and performance.
* Applying **DevSecOps principles**, including Static Application Security Testing (SAST) and Software Composition Analysis (SCA).
* Exploring **FinDevOps concepts** for cost-effective cloud-native operations.

---

## Frameworks Used

* **Kubernetes (K3s)**: Lightweight Kubernetes distribution for container orchestration.
* **Python (Flask/other microframeworks)**: Primary language for application services.
* **Docker**: Containerization platform.
* **GitHub Actions**: CI/CD automation.
* **Terraform**: Infrastructure as Code for provisioning.
* **Ansible**: Configuration management and K3s cluster setup.
* **Helm**: Kubernetes package manager.
* **Kustomize**: Kubernetes configuration customization.
* **Pytest**: Python testing framework.
* **Prometheus & Grafana**: Monitoring and alerting (planned/integrated).
* **Bandit**: Static Application Security Testing (SAST) for Python.
* **Trivy**: Software Composition Analysis (SCA) and vulnerability scanning.

---

## Tech Stack Overview

* **Languages:** Python
* **Containerization:** Docker
* **Orchestration:** Kubernetes (K3s)
* **CI/CD:** GitHub Actions
* **Infrastructure as Code:** Terraform, Ansible
* **Databases/Messaging:** PostgreSQL (persistent data), RabbitMQ (message broker), Redis (caching/temporary data)
* **Security Tools:** Bandit (SAST), Trivy (SCA)
* **Monitoring (Planned/Integrated):** Prometheus, Grafana

---

## Application Type

This project is a **web application** composed of multiple interconnected **microservices**. It includes both backend services (e.g., `audit-log-analysis`, `notification-service`) and a frontend dashboard (e.g., `event-audit-dashboard`).

---

## Directory Structure
This project is a dynamic and evolving learning initiative. Its status and ongoing development can be tracked via the [GitHub Project board](https://github.com/jojees/project-genesis/projects) and [GitHub Issues](https://github.com/jojees/project-genesis/issues).

The project is meticulously organized to separate application code from infrastructure, documentation, and CI/CD configurations. This structure promotes clarity, maintainability, and scalability.
```
.
â”œâ”€â”€ .github/                      # GitHub Actions workflows for CI/CD
â”œâ”€â”€ docs/                         # Project documentation (architecture, pillars, setup guides)
â”œâ”€â”€ infra/                        # Infrastructure as Code (Terraform for provisioning, Ansible for configuration)
â”‚   â”œâ”€â”€ terraform/                # Terraform configurations for base infrastructure
â”‚   â””â”€â”€ ansible/                  # Ansible playbooks and roles for configuration management (e.g., K3s installation)
â”œâ”€â”€ k8s/                          # Kubernetes manifests and Helm charts
â”‚   â”œâ”€â”€ base/                     # Base Kubernetes YAMLs for individual services (can be integrated into Helm)
â”‚   â”œâ”€â”€ charts/                   # Helm charts for the entire application and individual services
â”‚   â””â”€â”€ overlays/                 # Kustomize overlays for environment-specific configurations
â”œâ”€â”€ monitoring/                   # Configurations for Prometheus, Grafana, and alert rules
â”œâ”€â”€ reports/                      # Generated reports (e.g., test coverage XML)
â”œâ”€â”€ scripts/                      # Helper scripts for deployment, setup, etc.
â””â”€â”€ src/                          # Application source code (the 'AuditFlow Platform' microservices)
â”œâ”€â”€ audit_event_generator/
â”œâ”€â”€ audit-log-analysis/
â”œâ”€â”€ event-audit-dashboard/
â””â”€â”€ notification-service/
â””â”€â”€ tests/                # Unit and integration tests for each service
â”œâ”€â”€ .gitignore                    # Files and directories to ignore in Git
â”œâ”€â”€ .pytest.ini                   # Global Pytest configuration
â”œâ”€â”€ CODE_OF_CONDUCT.md
â”œâ”€â”€ CONTRIBUTING.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md                     # This file
â””â”€â”€ TODO.md                       # Project tasks and notes
```
For a more detailed breakdown of the directory contents, refer to the `docs/` directory.

**ğŸ¥ Want to see Project Genesis in action and follow its development?** Check out our video tutorials and development logs on our [YouTube Channel](https://www.youtube.com/@JojeesDevOpsStudio)!

---

## Main Entry Point or App Initializer

For each Python microservice within the `src/` directory, the main entry points are typically:
* `src/*/app.py` (e.g., `src/audit-event-generator/app.py`, `src/event-audit-dashboard/event_audit_dashboard/app.py`)
* `src/*/main.py` (e.g., `src/audit-log-analysis/audit_analysis/main.py`, `src/notification-service/notification_service/main.py`)

These files initialize the respective Flask applications, set up logging, connect to message brokers (RabbitMQ), and interact with databases (Postgres, Redis).

---

## Setup Instructions (High-Level)

The project emphasizes Infrastructure as Code (IaC) and automated deployments. Key setup steps include:

1.  **Prerequisites:** Install Git, Docker, Python 3.9+ with Poetry, Terraform CLI, Ansible, `kubectl`, and Helm CLI.
2.  **Infrastructure Provisioning:**
    * Review and adjust **Terraform configurations** in `infra/terraform/`.
    * Initialize and apply Terraform: `terraform init`, `terraform plan`, `terraform apply -auto-approve`.
    * Configure the **K3s cluster** on provisioned nodes using **Ansible** (update `infra/ansible/inventory/hosts.ini` and run `ansible-playbook -i inventory/hosts.ini playbooks/setup-k3s.yaml`).
3.  **Application Deployment:**
    * **Docker Images:** Built and pushed automatically to Docker Hub via GitHub Actions.
    * **Kubernetes Deployment:** Deploy the AuditFlow Platform using **Helm**. Navigate to the main Helm chart directory (e.g., `k8s/charts/events-app`), update dependencies (`helm dependency update`), and install (`helm install auditflow-platform . --namespace auditflow-platform --create-namespace -f values.yaml`).

Detailed instructions are available in the `docs/` directory, particularly `docs/setup.md`.

---

## Usage Instructions

Once deployed to Kubernetes:
* The **`event-audit-dashboard`** service provides a user interface to visualize audit events and alerts. Access will depend on Kubernetes service exposure (e.g., NodePort, LoadBalancer, Ingress).
* Other services (e.g., `audit-event-generator`, `audit-log-analysis`, `notification-service`) run as background processes, interacting via RabbitMQ and storing data in PostgreSQL or Redis.
* Monitoring tools (Prometheus, Grafana) would be used to observe application health and performance.

---

## Architecture Overview

The `AuditFlow Platform` is an **event-driven, microservice-based application**.
* **`audit_event_generator`**: Produces synthetic audit events.
* **`audit-log-analysis`**: Consumes events from RabbitMQ, performs analysis, and stores results (likely in Postgres or Redis).
* **`event-audit-dashboard`**: A web interface that fetches and displays audit events/alerts.
* **`notification-service`**: Handles alerts and notifications based on analysis outcomes.
* **`PostgreSQL`**: Relational database for persistent storage.
* **`RabbitMQ`**: Central message broker facilitating asynchronous communication between services.
* **`Redis`**: Key-value store for caching or temporary data.

Services communicate primarily via **RabbitMQ**, enabling a decoupled and scalable system. Kubernetes orchestrates these services, ensuring their availability and managing resources.

---

## Explanation of Key Modules/Components

* **`audit-event-generator` (Python Microservice):** Responsible for creating and publishing synthetic audit events to RabbitMQ.
* **`audit-log-analysis` (Python Microservice):** Consumes audit events from RabbitMQ, processes them (e.g., parsing, categorization), and stores the analyzed data. It likely interacts with Redis for temporary data and Postgres for persistent storage.
* **`event-audit-dashboard` (Python Web Application):** Provides a Flask-based web interface for users to visualize the processed audit events and alerts. It retrieves data from the backend services or databases.
* **`notification-service` (Python Microservice):** Subscribes to specific event streams from RabbitMQ or listens for triggers from the `audit-log-analysis` service, sending out notifications (e.g., email, alerts) based on defined rules. It interacts with Postgres for notification-related data.
* **`k8s/base`:** Contains the foundational Kubernetes YAML manifests for each service and infrastructure component (Postgres, RabbitMQ, Redis). These define Deployments, Services, StatefulSets, and PVCs.
* **`infra/terraform`:** Holds Terraform configurations to provision the underlying cloud infrastructure (e.g., VMs for K3s nodes) required for the Kubernetes cluster.
* **`infra/ansible`:** Contains Ansible playbooks to automate the installation and configuration of the K3s cluster on the provisioned infrastructure.
* **`docs/`:** Comprehensive documentation covering architecture, DevOps pillars, setup guides, and more.

---

## List of Dependencies and Scripts (Examples)

Dependencies for each Python service (`audit-event-generator`, `audit-log-analysis`, `event-audit-dashboard`, `notification-service`) are managed using `pyproject.toml` and `requirements.txt`. While specific contents vary per service, they typically include:

* **`Flask`**: For building web services.
* **`Pika`**: Python client for RabbitMQ.
* **`SQLAlchemy` / `Psycopg2`**: For PostgreSQL interaction.
* **`Redis`**: Python client for Redis.
* **`Gunicorn`**: WSGI HTTP Server.
* **`python-dotenv`**: For managing environment variables.
* **`pytest`**: For testing.
* **`bandit`**: For SAST.
* **`poetry`**: Python packaging and dependency management.

**Example from `src/audit-event-generator/pyproject.toml` (or similar for other services):**

```toml
[tool.poetry.dependencies]
python = "^3.9"
Flask = "^2.2.0"
pika = "^1.3.0"
python-dotenv = "^1.0.0"
gunicorn = "^20.1.0"
```

**Example from src/audit-event-generator/requirements.txt (auto-generated by poetry or manually maintained):**

```Flask==2.2.0
pika==1.3.0
python-dotenv==1.0.0
gunicorn==20.1.0
```
**Common scripts (conceptual, based on README.md and project structure):**

* `terraform init/plan/apply`: For infrastructure provisioning (infra/terraform).
* `ansible-playbook`: For K3s cluster setup (infra/ansible).
* `docker build/push`: For building and pushing service images (automated via GitHub Actions).
* `helm install/upgrade`: For deploying applications to Kubernetes (k8s/charts).
* `pytest`: For running unit/integration tests within src/*/tests/.
* `bandit`: For running SAST scans.
* `trivy fs / trivy image`: For SCA and vulnerability scanning.

---

## CI/CD Pipeline Details

The project leverages **GitHub Actions** for its **Continuous Integration and Continuous Delivery (CI/CD)** pipelines, specifically designed for Python microservices and Docker image management. The workflows are structured for efficiency, reusability, and robust security integration.

### Key Workflows:

* **`.github/workflows/build-python-services.yml` (Main CI Workflow):**
    * **Trigger:** Automatically runs on `push` events to `main`, `staging`, and `dev` branches.
    * **Optimized Builds:** Utilizes `dorny/paths-filter@v3` to detect changes in specific service directories (`src/event-audit-dashboard/`, `src/notification-service/`, `src/audit-log-analysis/`, `src/audit-event-generator/`).
    * **Conditional Execution:** Only triggers build and scan jobs for services that have undergone changes, optimizing pipeline execution time and resource usage.
    * **Reusable Workflow Calls:** Calls the `build-single-service.yml` reusable workflow for each modified service, passing necessary parameters like `service_name`, Docker credentials, and Git metadata.

* **`.github/workflows/build-single-service.yml` (Reusable Workflow):**
    * **Purpose:** Encapsulates the logic for building, pushing Docker images, and performing security scans for a *single* Python microservice. This promotes reusability and reduces duplication across multiple service pipelines.
    * **Inputs:** Requires `service_name`, `docker_org`, `docker_repo_prefix`, `ref_name` (branch name), `github_sha` (commit SHA), and Docker Hub credentials as secrets.
    * **Multi-architecture Builds:** Configured to build Docker images for `linux/amd64` and `linux/arm64` platforms, ensuring broad compatibility.
    * **Image Tagging:** Automatically generates Docker image tags based on the commit SHA, branch name (e.g., `main` gets `latest`, `dev` gets `dev`, `dev-snapshot`), and a combination of `docker_org` and `service_name`.
    * **Caching:** Uses GitHub Actions cache (`type=gha`) to speed up Docker image builds.

### Integrated Security Scans (DevSecOps):

Both workflows implicitly, via the reusable workflow, integrate security scanning at different stages of the CI/CD pipeline.

* **Static Application Security Testing (SAST):**
    * **Tool:** **Bandit** (`bandit -r . -ll -f sarif -o bandit_results.sarif`).
    * **Timing:** Runs *before* Docker image creation on the source code of each Python service.
    * **Output:** Generates SARIF format reports (`bandit_results.sarif`) which are then uploaded to **GitHub Code Scanning** (`github/codeql-action/upload-sarif@v3`) for centralized vulnerability management.
* **Software Composition Analysis (SCA) & Vulnerability Scanning:**
    * **Tool:** **Trivy** (`aquasecurity/trivy-action@master`).
    * **Types of Scans:**
        * **Filesystem Scan (`scan-type: 'fs'`):** Scans the project's dependencies (e.g., `requirements.txt`, `pyproject.toml`) for known vulnerabilities (`vuln`) and secrets *before* image build.
        * **Image Scan (`image-ref`):** Scans the *built Docker image* for vulnerabilities in OS packages, programming language dependencies, and misconfigurations (`vuln,secret,misconfig`).
    * **Output:** Generates SARIF format reports (e.g., `trivy-dependency-results_*.sarif`, `trivy-image-results_*.sarif`) which are uploaded to **GitHub Code Scanning**, providing a comprehensive view of supply chain and image-level security.
    * **Non-Blocking:** Scans are configured with `exit-code: '0'` to avoid failing the build immediately, allowing security results to be collected even if issues are found, which can be reviewed in GitHub's security tab.

This robust CI/CD setup ensures that code changes are continuously integrated, built into multi-architecture Docker images, and thoroughly scanned for security vulnerabilities before deployment.

---
## Kubernetes Base Configuration Details (k8s/base) â˜¸ï¸

The `k8s/base` directory contains the foundational Kubernetes YAML manifests for the **AuditFlow Platform's microservices** and their supporting infrastructure (PostgreSQL, RabbitMQ, Redis). These files provide the core, un-customized declarations for Deployments, Services, StatefulSets, and PersistentVolumeClaims. While `k8s/charts` and `k8s/overlays` are planned for future development to handle templating and environment-specific customizations, `k8s/base` serves as the initial, declarative setup.

### Core Principles and Object Types:

* **Deployments**: Define and manage the desired state for the application microservices (e.g., `audit-event-generator`, `audit-log-analysis`, `event-audit-dashboard`, `notification-service`), ensuring a specified number of replicas are running.
* **Services**:
    * **`ClusterIP`**: Used for internal communication between services within the Kubernetes cluster. Most application and infrastructure services (e.g., `rabbitmq-service`, `postgres-service`, `audit-log-analysis-service`) are exposed via `ClusterIP`.
    * **`NodePort`**: The `event-audit-dashboard-service` is exposed as a `NodePort` (specifically `30080`), allowing external access to the dashboard via any Kubernetes node's IP address.
* **StatefulSets**: Used for stateful applications like PostgreSQL, ensuring stable network identities and ordered, graceful deployment/scaling.
* **PersistentVolumeClaims (PVCs)**: Request and manage persistent storage for stateful applications (e.g., `postgres-pv-claim` for PostgreSQL), ensuring data durability across pod restarts or redeployments. Uses the `local-path` storage class, typical for K3s local storage.
* **Resource Management**: All Deployments include `requests` and `limits` for CPU and Memory, promoting efficient resource utilization and preventing resource contention.
* **Health Checks**: **Liveness and Readiness Probes** are configured for critical application services, enhancing resilience by ensuring Kubernetes routes traffic only to healthy, ready instances and restarts unhealthy ones.
* **Environment Variables**: Service-to-service communication configurations (like `RABBITMQ_HOST`, `REDIS_HOST`, `PG_HOST`) are injected into containers via environment variables, referencing the internal Kubernetes service names.
* **Secret Management**: Sensitive information, such as PostgreSQL database credentials (`PG_DB`, `PG_USER`, `PG_PASSWORD`), is securely referenced from a **Kubernetes Secret** (e.g., `postgres-credentials`), adhering to security best practices.
* **Observability Hooks**: Services include specific labels (`prometheus_scrape: "true"`) and annotations (`prometheus.io/scrape`, `prometheus.io/port`) to facilitate automatic discovery and scraping of metrics by **Prometheus**, indicating a strong focus on monitoring.

***
### Components in `k8s/base`:

* **`audit-event-generator`**: Deployment and ClusterIP Service. Generates events and connects to RabbitMQ.
* **`audit-log-analysis`**: Deployment and ClusterIP Service. Consumes events from RabbitMQ and interacts with Redis.
* **`event-audit-dashboard`**: Deployment and NodePort Service. Provides the web UI and connects to the Notification Service.
* **`notification-service`**: Deployment and ClusterIP Service. Handles alerts, connects to RabbitMQ and PostgreSQL. Securely retrieves PostgreSQL credentials from a Secret.
* **`postgres`**: PersistentVolumeClaim, ClusterIP Service, and StatefulSet. Provides a durable PostgreSQL database instance.
* **`rabbitmq`**: Deployment and ClusterIP Service. Acts as the central message broker for inter-service communication.
* **`redis`**: Deployment and ClusterIP Service. Serves as a key-value store, currently configured with `emptyDir` for non-persistent storage.

---
## Monitoring & Observability Strategy ğŸ“ˆ
Currently, the primary focus for observability is on Prometheus metrics scraping, indicated by labels and annotations in the Kubernetes base manifests. Each Python microservice is expected to expose a `/metrics` endpoint (e.g., on port 8000 or 8001) for Prometheus to collect time-series data.

**Future Enhancements (Planned/To Be Detailed):**
* **Logging Strategy:** Details on structured logging, centralized log aggregation (e.g., ELK stack, Grafana Loki), and the implementation of correlation IDs for tracing requests across services are planned.
* **Alerting:** Configuration for Prometheus Alertmanager rules and notification channels will be added.
* **Distributed Tracing:** Future consideration for implementing distributed tracing (e.g., OpenTelemetry, Jaeger) to visualize inter-service request flows.

---

## Error Handling & Resilience Patterns ğŸ›¡ï¸
As a microservices architecture, the system's resilience is critical. While specific patterns like retries and circuit breakers are not explicitly detailed in the current configuration files, these are essential considerations for a robust distributed system.

**Future Enhancements (Planned/To Be Detailed):**
* **Inter-service Communication Failures:** Specific strategies for handling transient network errors, including retries with exponential backoff.
* **Circuit Breakers/Bulkheads:** Implementation details for these patterns to prevent cascading failures.
* **Graceful Degradation:** How the system will behave when dependent services are unavailable.
* **Database Error Handling:** Mechanisms for managing database connection errors, transaction failures, and retries.

---

## API Endpoints & Communication Protocols ğŸ”—
The core inter-service communication relies heavily on **RabbitMQ** for an event-driven architecture, enabling asynchronous message exchange between components.

**Current Knowns:**
* **Internal Communication:** Services communicate via RabbitMQ queues (e.g., `audit_events`, `audit_alerts`).
* **RESTful APIs:** The `event-audit-dashboard` is a web application, implying it exposes HTTP endpoints, and the `notification-service` is noted to have a future API (port 8000).

**Future Enhancements (Planned/To Be Detailed):**
* **Detailed API Endpoints:** Specific RESTful API endpoints exposed by services, their methods, and expected request/response formats.
* **API Documentation:** Whether OpenAPI/Swagger definitions are used or planned for internal/external APIs.
* **Other Protocols:** If other communication protocols (e.g., gRPC) are used for specific inter-service interactions.

---

## Deployment Strategy & Rollbacks ğŸ”„
The deployment process relies on GitHub Actions for building Docker images and a Kubernetes base configuration `(k8s/base)` for defining the desired state.

**Current Knowns:**
* **Initial Deployment:** Based on the `infra/terraform` and `infra/ansible` details, the initial infrastructure provisioning and K3s cluster setup are automated. Application deployment is via direct application of `k8s/base` manifests, or conceptually via Helm (once `k8s/charts` is populated).
* **Rolling Updates:** Kubernetes Deployments, by default, employ a rolling update strategy when `replicas` are updated or the `template` changes.

**Future Enhancements (Planned/To Be Detailed):**
* **Automated Rollback Mechanism:** Specific strategies and tooling (e.g., leveraging Helm's rollback capabilities) for quickly reverting to a previous stable version in case of a failed deployment.
* **Canary Deployments/Blue-Green Deployments:** Advanced deployment strategies for minimizing risk during new releases.
* **Traffic Management:** How ingress controllers, service meshes, or other tools manage traffic during deployments or for A/B testing.

---

## Database Schema & Migrations ğŸ—„ï¸
The database schema and any updates are currently managed directly within the **application codebase** of the services that interact with PostgreSQL (primarily the `notification-service`). There is no separate database migration tool (like Alembic, Flyway, or Liquibase) explicitly mentioned or configured at this stage.

**Further Understanding:** To understand the specific schema and its evolution, a review of the database interaction code within the relevant application services (e.g., ORM models, SQL statements) would be necessary.

---

## Application Details

### Audit Event Generator Service (src/audit-event-generator) âš™ï¸
* **Role**: The primary source of simulated audit events for the AuditFlow Platform.
* **Functionality**: Continuously generates diverse audit events (e.g., user logins, file modifications) and publishes them to the `audit_events` RabbitMQ queue. It also provides an API endpoint (`/generate_event`) for on-demand event creation.
* **Output**: Produces raw audit event messages into the `audit_events` RabbitMQ queue.
* **Dependencies**: Primarily relies on **RabbitMQ** for event publishing.
* **Observability**: Exposes `/healthz` and `/metrics` endpoints for health checks and Prometheus integration.
* **Detailed Context**: For in-depth information, refer to [src/audit-event-generator/CONTEXT.md](src/audit-event-generator/CONTEXT.md).
---
### Audit Log Analysis Service (src/audit-log-analysis) ğŸ•µï¸

* **Role**: A critical backend service that **consumes raw audit events** from the `audit_events` RabbitMQ queue.
* **Functionality**: Performs **real-time analysis** on these events (e.g., detecting failed login bursts, sensitive file modifications) and **generates alerts**.
* **Output**: Publishes detected **alerts** to a separate `audit_alerts` RabbitMQ queue for downstream services like the Notification Service.
* **Dependencies**: Relies on **RabbitMQ** for event consumption and alert publishing, and **Redis** for stateful analysis (e.g., tracking login attempts).
* **Observability**: Exposes `/healthz` and `/metrics` endpoints for health monitoring and Prometheus integration.
* **Detailed Context**: For in-depth information, refer to [src/audit-log-analysis/CONTEXT.md](src/audit-log-analysis/CONTEXT.md).
---
### Event Audit Dashboard Service (src/event-audit-dashboard) ğŸ–¥ï¸
* **Role:** The frontend web application of the AuditFlow Platform.
* **Functionality:** Provides a user interface to visualize audit alerts. It fetches recent alerts from the `Notification Service` API and displays them on a dashboard, also offering detailed views for individual alerts.
* **Output:** Presents a browser-based dashboard for human consumption.
* **Dependencies:** Primarily relies on the Notification Service (via HTTP API calls) to retrieve alert data.
* **Observability:** Exposes a `/healthz` endpoint for health checks.
* **Deployment:** Uses Gunicorn for production readiness.
* **Detailed Context:** For in-depth information, refer to src/event-audit-dashboard/CONTEXT.md.
---
### Notification Service (src/notification-service) ğŸ””
* **Role:** The central backend service for **storing and retrieving audit alerts**.
* **Functionality:** Consumes **alert messages from RabbitMQ**, persists them into a **PostgreSQL database**, and exposes a **RESTful API** for other services (like the dashboard) to query these alerts.
* **Output:** Stores alert data in PostgreSQL and serves it via an API.
* **Dependencies:** Relies on **RabbitMQ** (for alert ingestion) and **PostgreSQL** (for data storage).
* **Observability:** Exposes a `/healthz` endpoint for health checks and API endpoints for alert retrieval.
* **Deployment:** Built with **Quart** and served by **Uvicorn** for asynchronous, production-grade performance.
* **Detailed Context:** For in-depth information, refer to src/notification-service/CONTEXT.md.

---

## ğŸ§ª Testing Philosophy & Strategy Summary

Our approach to unit and integration testing is guided by practical experience, long-term maintainability, and insights from the broader development community. Hereâ€™s a summary of key takeaways and how they shape our testing practices:

---

### ğŸ”¹ General Guidelines

- **No arbitrary coverage targets** (e.g. 100%) â€” coverage is not a guarantee of quality.
- Focus on **high-value coverage**: business logic, edge cases, data validation, and workflows with real-world consequences.
- Prioritize **breadth over depth**: it's better to have all files partially tested than a few files exhaustively covered.

---

### ğŸ”¹ Unit Testing

- Use unit tests to verify **core logic**, **critical transformations**, and **small testable functions**.
- Avoid over-testing trivial code (getters, boilerplate, etc.).
- Keep tests meaningful and easy to understand â€” they should explain what the code does and catch regressions early.

---

### ğŸ”¹ Integration Testing

- Integration tests simulate how components interact under real conditions.
- Ideal for:
  - HTTP routes and controllers
  - Database interactions
  - Service boundaries
- Integration tests often provide more realistic coverage than isolated unit tests.

---

### ğŸ”¹ On Test-Driven Development (TDD)

- TDD can help guide design and ensure correctness, especially in complex or evolving modules.
- However, strict TDD can lead to **test bloat** and **poor design** when followed dogmatically.
- Use it **when it adds value**, not as a mandatory rule.

---

### ğŸ”¹ Coverage Philosophy

- **Test what matters**, not just what exists.
- Treat coverage as a **feedback tool**, not a goal.
- Use integration and system tests to validate behavior from the user's point of view.
- Maintain tests that **prevent regressions**, not tests that just exercise lines of code.

---

### ğŸ§  Summary Quote

> â€œThe right number of tests is not a number â€” it's the set of tests that gives you confidence to ship and change code safely.â€

---
